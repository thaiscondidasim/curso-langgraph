# Li√ß√£o 6 - Chatbot com sumariza√ß√£o de mensagens e mem√≥ria em banco de dados externo

Neste trecho, o autor mostra como tornar um **chatbot mais robusto para conversas de longa dura√ß√£o**, com **persist√™ncia de mem√≥ria entre sess√µes**, usando:

1. **Resumo cont√≠nuo da conversa** (para compress√£o e economia de tokens).
2. **Checkpointer com persist√™ncia local** via **SQLite**.
3. **Persist√™ncia autom√°tica com Postgres** via **LangGraph Studio**.

Essas abordagens resolvem a limita√ß√£o da mem√≥ria "tempor√°ria" que s√≥ dura enquanto o notebook estiver ativo.

Constru√≠mos um chatbot que suporta **conversas longas** de duas maneiras:

1. **Mem√≥ria persistente na sess√£o**: usamos um *checkpointer em mem√≥ria*, que mant√©m o hist√≥rico da conversa enquanto o notebook estiver ativo.
2. **Resumos da conversa**: ap√≥s certo n√∫mero de mensagens (ex: 6), o chatbot resume as mensagens antigas. Isso **reduz o uso de tokens** e torna mais vi√°vel manter conversas longas.

---

### ‚ö†Ô∏è Limita√ß√£o

Esse chatbot **n√£o √© persistente indefinidamente**, porque usamos um **checkpointer em mem√≥ria**, que perde os dados ao encerrar o notebook.

---

### üí° Solu√ß√£o: usar banco de dados externo

O **LangGraph** suporta diferentes checkpointers que funcionam com **bancos de dados externos**, como:

- **SQLite** (banco de dados leve e local);
- **Postgres** (mais robusto, usado em produ√ß√£o).

## Sqlite

Um bom ponto de partida aqui √© o [checkpointer SqliteSaver](https://langchain-ai.github.io/langgraph/concepts/low_level/#checkpointer).

O Sqlite √© um banco de dados SQL [pequeno, r√°pido e muito popular](https://x.com/karpathy/status/1819490455664685297).

Se fornecermos `":memory:"`, ele criar√° um banco de dados SQLite na mem√≥ria.

```python
import sqlite3
# In memory
conn = sqlite3.connect(":memory:", check_same_thread = False)
```

Mas, se fornecermos um caminho para o banco de dados, ele criar√° um banco de dados para n√≥s!

```python
# pull file if it doesn't exist and connect to local db
!mkdir -p state_db && [ ! -f state_db/example.db ] && wget -P state_db https://github.com/langchain-ai/langchain-academy/raw/main/module-2/state_db/example.db

db_path = "state_db/example.db"
conn = sqlite3.connect(db_path, check_same_thread=False)
```

```python
# Here is our checkpointer 
from langgraph.checkpoint.sqlite import SqliteSaver
memory = SqliteSaver(conn)
```

Vamos redefinir nosso chatbot.

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage

from langgraph.graph import END
from langgraph.graph import MessagesState

model = ChatOpenAI(model="gpt-4o",temperature=0)

class State(MessagesState):
    summary: str

# Define the logic to call the model
def call_model(state: State):
    
    # Get summary if it exists
    summary = state.get("summary", "")

    # If there is summary, then we add it
    if summary:
        
        # Add summary to system message
        system_message = f"Summary of conversation earlier: {summary}"

        # Append summary to any newer messages
        messages = [SystemMessage(content=system_message)] + state["messages"]
    
    else:
        messages = state["messages"]
    
    response = model.invoke(messages)
    return {"messages": response}

def summarize_conversation(state: State):
    
    # First, we get any existing summary
    summary = state.get("summary", "")

    # Create our summarization prompt 
    if summary:
        
        # A summary already exists
        summary_message = (
            f"This is summary of the conversation to date: {summary}\n\n"
            "Extend the summary by taking into account the new messages above:"
        )
        
    else:
        summary_message = "Create a summary of the conversation above:"

    # Add prompt to our history
    messages = state["messages"] + [HumanMessage(content=summary_message)]
    response = model.invoke(messages)
    
    # Delete all but the 2 most recent messages
    delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:-2]]
    return {"summary": response.content, "messages": delete_messages}

# Determine whether to end or summarize the conversation
def should_continue(state: State):
    
    """Return the next node to execute."""
    
    messages = state["messages"]
    
    # If there are more than six messages, then we summarize the conversation
    if len(messages) > 6:
        return "summarize_conversation"
    
    # Otherwise we can just end
    return END
```

Agora, basta recompilar com nosso checkpointer sqlite.

```python
from IPython.display import Image, display
from langgraph.graph import StateGraph, START

# Define a new graph
workflow = StateGraph(State)
workflow.add_node("conversation", call_model)
workflow.add_node(summarize_conversation)

# Set the entrypoint as conversation
workflow.add_edge(START, "conversation")
workflow.add_conditional_edges("conversation", should_continue)
workflow.add_edge("summarize_conversation", END)

# Compile
graph = workflow.compile(checkpointer=memory)
display(Image(graph.get_graph().draw_mermaid_png()))
```

![image.png](attachment:3cd1f6b3-bd86-462a-ad9f-21c559417fa0:image.png)

---

### üõ†Ô∏è Exemplo com SQLite

1. Importamos o m√≥dulo do SQLite.
2. Se passarmos `"memory"` na conex√£o, o banco funciona em mem√≥ria (igual ao anterior).
3. Se passarmos um **caminho de arquivo**, ele cria/usa um banco local persistente.

---

### üîó Cria√ß√£o do checkpointer

- Criamos o checkpointer com SQLite.
- Chamamos isso de `memory`.
- Conectamos.
- Criamos o chatbot igual aos exemplos anteriores.

---

### üîÅ Fluxo da conversa

- Come√ßamos com `"Oi, sou o Lance"`.
- O LLM responde.
- Ap√≥s 6 mensagens, o grafo dispara um resumo.
- O resumo √© salvo na chave `summary` do estado.

Esse fluxo segue o mesmo padr√£o j√° demonstrado: a cada passo, usamos o `call_model`, que checa se existe um resumo e o adiciona ao contexto.

Agora, basta recompilar com nosso checkpointer sqlite.

```python
# Create a thread
config = {"configurable": {"thread_id": "1"}}

# Start conversation
input_message = HumanMessage(content="hi! I'm Lance")
output = graph.invoke({"messages": [input_message]}, config) 
for m in output['messages'][-1:]:
    m.pretty_print()

input_message = HumanMessage(content="what's my name?")
output = graph.invoke({"messages": [input_message]}, config) 
for m in output['messages'][-1:]:
    m.pretty_print()

input_message = HumanMessage(content="i like the 49ers!")
output = graph.invoke({"messages": [input_message]}, config) 
for m in output['messages'][-1:]:
    m.pretty_print()
```

```python
/var/folders/l9/bpjxdmfx7lvd1fbdjn38y5dh0000gn/T/ipykernel_18873/2173919996.py:55: LangChainBetaWarning: The class `RemoveMessage` is in beta. It is actively being worked on, so the API may change.
  delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:-2]]
================================== Ai Message ==================================

Hello again, Lance! It's great to hear from you. Since you like the 49ers, is there a particular player or moment in their history that stands out to you? Or perhaps you'd like to discuss their current season? Let me know!
================================== Ai Message ==================================

Your name is Lance! How can I assist you today? Would you like to talk more about the San Francisco 49ers or something else?
================================== Ai Message ==================================

That's awesome, Lance! The San Francisco 49ers have a rich history and a passionate fan base. Is there a specific aspect of the team you'd like to discuss? For example, we could talk about:

- Their legendary players like Joe Montana and Jerry Rice
- Memorable games and Super Bowl victories
- The current roster and season prospects
- Rivalries, like the one with the Seattle Seahawks
- Levi's Stadium and the fan experience

Let me know what interests you!
```

---

### üîÑ Teste de persist√™ncia

1. Executamos o notebook e salvamos a conversa.
2. **Reiniciamos o kernel** (interrompendo tudo).
3. Se fosse um checkpointer em mem√≥ria, **perder√≠amos tudo**.
4. Como estamos usando o SQLite, os dados est√£o **salvos em disco**.
5. Recriamos o grafo e... **o estado persiste!**
    
    ‚úÖ Ao passar o `thread_id`, recuperamos o estado anterior da conversa.
    

---

### üì¶ Uso com LangGraph Studio

O **LangGraph Studio** tem uma **camada de persist√™ncia embutida**, que:

- Funciona via API;
- Usa **PostgreSQL** por tr√°s;
- Permite manter o hist√≥rico de todas as conversas (**threads**) localmente ou remotamente.

---

### üß™ Exemplo pr√°tico no Studio

1. Abrimos o projeto `chatbot.py` no editor.
2. Empacotamos com a API do LangGraph.
3. A API automaticamente **adiciona persist√™ncia** via Postgres.
4. Executamos o bot no Studio:
    - `Oi, sou o Lance`
    - `Gosto dos 49ers`
    - `Quem √© o t√©cnico?`
    - `Me fale sobre o pai dele` (Mike Shanahan)
5. Ap√≥s a sexta mensagem, o grafo **gera um resumo da conversa**.

---

### üßµ Threads e continuidade

- Cada conversa √© uma **thread** com `thread_id`.
- Podemos criar uma nova thread:
    - `"Oi, sou o Lance"`
    - `"Quem √© o maior rival dos 49ers?"` ‚Üí Cowboys, anos 80, 90 etc.
- Podemos voltar √† thread anterior:
    - `"Quem foi o melhor jogador do Mike Shanahan?"`
    - E o sistema continua **do ponto em que paramos**, com o contexto salvo.

---

### ‚úÖ Conclus√£o

| Estrat√©gia | O que permite fazer |
| --- | --- |
| `MemorySaverCheckpointer` | Persist√™ncia em mem√≥ria (at√© encerrar a sess√£o do notebook) |
| `SQLiteCheckpointer` | Persist√™ncia local (salva no disco com SQLite) |
| **LangGraph Studio (Postgres)** | Persist√™ncia autom√°tica, empacotada via API com suporte a m√∫ltiplas threads |

---

üìå **Benef√≠cios combinados**:

- Conversas **longas e cont√≠nuas**, sem perda de contexto.
- Compress√£o de mensagens antigas com **resumo autom√°tico**.
- Persist√™ncia mesmo ap√≥s **rein√≠cio do sistema** ou mudan√ßa de ambiente.

---

Se quiser, posso gerar um exemplo real com `LangGraph + SQLite` ou te ajudar a rodar esse fluxo completo localmente ou na Studio. Deseja seguir por esse caminho?